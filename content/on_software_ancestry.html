<h1>On Knowing Your Software Roots</h1>
<p>&emsp;I know very few software developers who like development so much as to do it in their free time as well as for work. However, I am one of those developers. Since the love of programming hasn't quite yet been beaten out of me by the tedious monotony of a 40 hour work week doing precisely that, I spend a lot of my extra time either coding or learning about code. Typically, this amounts to some trivial endeavor to produce a set of desired outputs or diagnostic information about performance of some algorithm to the console. However, it's no secret to anyone I've ever talked to about development for even a few minutes that my driving interests are in simulation and game development. As such, it's probably no surprise that the first non-trivial project I've taken on in my free time is a source port of the original, open sourced Doom engine (which can be found <a href="https://github.com/id-Software/DOOM">here</a>) from the original C into .NET framework in C#. (As of this writing, I still haven't posted any of my code up to GitHub for review or use by others, but once there are solid functional components, I will.)</p>
<p>&emsp;Prior to really learning the source code, I first had to learn the differences between the highly abstracted Java/C#/OOP paradigm I was educated on, and the lower-level, imperative-paradigm of C. Now I should point out that there was exactly one reason I started this project: I love Doom. I was raised on the game. In fact, it is one of the earliest video-gaming memories I have, and one of the fondest. I wanted to take on a more substantial project and nothing made more sense than learning the game that got me curious about programming, computing, and graphics in the first place. And while my intentions were initially no more complicated than that, it turned out to be an unintentionally fantastic decision. And the value of the decision boils down to the fact that the source code I would have to learn is incredibly old. Well... "old" in computing terms. The game only just hit drinking age last year, so it's not exceptionally old relative to, like, the whole history of things. But in terms of computing, two years amounts to two decades of growth and development, and two decades amounts to centuries of change.</p>
<h2>Some Background</h2>
<p>&emsp;To make it clear why the age of the source code is an important factor in the usefulness of my project, I should provide some background on me. I started school in 2006, completing two degrees in Philosophy and Computer Science by the time I was done in 2013. At VCU, the language of choice for teaching students was Java. This seems to be growing in popularity as the core teaching language for universities. It was designed as an object-oriented from the ground up (as opposed to C++, which is mostly an object-oriented/class-based extension of the otherwise imperative C), it's open-source, it's free to install and use -- as are most of the IDEs for it -- and it's portable across pretty much all systems. It makes a ton of sense for an introductory language. There's plenty of literature and it will get kids started programming right!</p>
<p>&emsp;Except it won't.</p>
<p>&emsp;I got to school with no programming exposure or experience whatsoever. I remember hearing all of these positive attributes of Java and wondering why anyone would program in anything else. It seemed like a gift from on high. Then I remembered learning that Java has "automated garbage collection", and that some programmers considered this to be a draw-back of Java, performance-hampering and intrusive. And that was all I learned about it.</p>
<p>&emsp;This was in my second programming class. I thought 300 lines was a <i>mountain</i> of code. The concept of recursion was drilling a deep hole into my cranium and making everything I previously thought of as straight-forward and easy suddenly puzzling, and challenging. There were strange concepts that I was only just learning even existed that other (smarter) people were using to do amazing things like create inencryption protocols and produce language-parsing spam filters and render visually stunning images of three-dimensional scenes with accurate dynamic lighting and surface properties. I wanted to learn about how any of this was even possible, let alone how people managed to accomplish and improve upon these things year after year. And then our professor told us that Java had this garbage-collecting mechanism, which is sometimes considered a draw-back, but that we didn't need to know how it worked, because it worked silently, in the background, and would save us from ourselves.</p>
<p>&emsp;I was <i>so curious!</i> By that point, I knew what garbage memory was, that it was the occasional side-effect of the ever-changing nature of the stack-frame; sometimes references are lost. I was told that this 'garbage' was collected by the VM anyway and not to worry. But I did worry. I worried about how frequently this mechanism would hijack the processing resources available to my application to clean up behind me. I wondered <i>how</i> it knew what the hell to clean up in the first place. My professor was basically telling us that there were programmers who were so much better at programming than we were, they could write a program that knew, even better than we did, whether a piece of memory would had ceased to be useful in the programs <i>we ourselves were writing</i>. They didn't even have to look at our code. They just knew what it would look like when we were sloppy, and would clean up after us.</p>
<p>&emsp;That was the first time I began to doubt the unassailable 'goodness' of Java. This was something whose very nature piqued my curiosity, but my professors just brushed the whole concept under the rug and expected us to move on. I was more than a little frustrated with this approach, to say the least. I asked how the mechanism was implemented but was told that it would take up too much class time to explain. I wanted to learn it on my own, but as soon as I tried, my own inexperience illuminated with the light of a thousand suns and I realized it was something that would have to wait. For the time being, I would have to trust that the garbage collector would do its job.</p>
<h2>The Turning-Point</h2>
<p>&emsp;A few semesters later, as I was sitting in my compilers class, the professor told us why Java was the language of choice for the VCU Computer Science program: because it was safe. It was that simple. According to him, the program originally used Pascal as its core language and then, once it was established enough to be trust-worthy and useful, they switched right over to Java. At no point did VCU teach C or C++ in its CS department (other than specific 'topics' classes you could take, occasionally) because they didn't want to give novice programmers the amount of control that comes with C. In my professors words: "It's too easy to brick your machine with C for us to trust freshmen to use it safely."</p>
<p>&emsp;Even though I totally understood that perspective, I was still a little annoyed. The reason I wanted to program in the first place was because I wanted to <i>control my machine.</i> I wanted to know exactly what was going through the silicon at any given moment when one of my programs was executing. I wanted to know how I could make <i>fucking silicon</i> put realistic 3D images on a screen! Or respond to user input or play music. That idea felt dismissive and insulting in the same way that the hand-waving about Java's garbage-collector did. The very idea that I would get through my entire formal education without any sort of exposure to that level of control, to that minimal separation from the machine seemed like a failure on the part of whoever designed the curriculum.</p>
<p>&emsp;To my mind, I was being deprived of something key to programming, and I knew I'd have to learn it on my own. Unfortunately, as with the garbage-collector, my desire to learn about it was drastically outweighed by my inabilty to find the time or resources to do so. The problem of learning very-low-level programming languages was one I couldn't solve.</p>
<p>&emsp;Of course, as the years go on and I continue to learn more about software development and engineering, languages have become more of a triviality than anything else. I recognize each one as a different means to the same end, and each with their own strengths and weaknesses. I've figured out that my education was about how to <i>approach</i> solving programming problems, and not about how to solve them.</p>
<h2>The Consequences</h2>
<p>&emsp;Fast-forward to today, and the source-port of Doom. With a couple text books and quite a few years more experience, learning and really <i>groking</i> C happened with relative ease. However, in doing so (again, for the sole purpose of recreating a game that has been recreated more times than any one man can count), I focused a spotlight on the biggest gap in my formal education. A gap which more and more CS graduates are leaving school without any knowledge of or desire to fill. I realized why it was such a fortunate decision on my part to take on this project. Even if I don't finish it (which I probably won't because, unless I have a compelling reason not to, I usually stop working on personal projects as soon as I stop learning new concepts and start doing the leg-work that accounts for most of any development task), I will have come away with something I didn't even know I needed to know. Because of this project, I learned about <i>pointers</i>.</p>
<p>&emsp;Now obviously, a lot of students will have learned about the difference between 'pass by reference' and 'pass by value' over the course of their education. It's a pretty essential concept when working with highly-abstracted, managed code like Java or C#. It's a core component to any meaningful understanding of execution scope. However, in the context of Java and education, it is sufficient to understand the difference as "the object you passed in at the function invocation vs. a copy of that object being made for use by a function". No understanding of memory addressing and pointers necessary. Just "object vs. copy of object". At VCU, we were told that this distinction is sufficient to write functional code and understand the work of our algorithms, but when I started learning C and reading its use in a widely distributed, production-level game engine, I realized that such a rudimentary understanding of 'pass by reference' really <i>isn't</i> sufficient. Pointers are such a huge component of how your code is translated into a set of runtime-level instructions that accurately maps to your source code and I left school without a clue as to the extent to which they are used.</p>
<p>&emsp;The most frustrating thing about this gap in my knowledge was the fact that I wasn't the only one who suffered from it. It's not unreasonable to assume that everyone graduating from VCU, and indeed many universities with fairly reputable CS departments, is leaving with this huge blank spot in their education. We are given highly abstracted, theoretical discussions and concepts about how machines perform the work we tell them to, but that's not enough. We aren't given a clear picture of the cost of our implementation decisions in terms of the memory footprint of our programs, or the impact on runtime one algorithm might have that wouldn't exist with another functionally equivalent algorithm. As a result, we're producing more and more graduates producing sloppy, resource-hungry code where there are leaner solutions available.</p>
<p>&emsp;If this makes me sound elitist, or like some crotchety old man shouting at kids to get their nested loops out of my recursion, allow me a moment to defend myself. I happen to love high-level languages. I think abstracting away that low-level memory management is one of the greatest things language designers could have done because it will ultimately allow more people to write code. If a developer can focus their efforts on the program they want to write, instead of how that program will fit and be organized on the multiple gigabytes of memory it will be loaded onto, they will undoubtedly produce a more focused solution. Or if someone would otherwise be turned off from writing a useful program because of having to deal with pointer management, but can suddenly start making useful, entertaining, or otherwise engaging applications for an audience that is seeking them, then abstraction is a god-send for the both the developer and their audience. Lowering the barrier of entry to software development is good for everyone because it won't stop people who want to make hardware-pushing, intensely optimized programs with C or x86 assembly code from making it. However, it may allow someone to make their brilliant idea a reality who otherwise wouldn't have. Everyone wins. Or at least no one loses.</p>
<p>&emsp;That being said though, I still think leaving out that deeper understanding of how code is being executed at the machine level is a mistake in terms of a CS curriculum. Students graduating with those degrees are expected to be software developers and engineers, and if we continue to graduate people who have no knowledge of how those mechanisms are saving them from themselves, the value of a CS degree will become more and more dubious.</p>
<p>&emsp;At the end of the day, I think anyone writing code should be able to, when necessary, think about their source code as a direct interface between their abstract solution design and the runtime environment in which it will be executed. What your runtime is will change depending on needs. Whether your needs are for portability, or for maximum performance, or for the availability of certain system resources, your runtime might be anything from the operating system's application tier, to a browser, to the very hardware of the machine. You might not need to think in terms of memory pointers, but in terms of how many characters an interpreter will have to scan before it can parse a variable name. Whatever the case though, you should be able to think about what your code means in terms of the instructions that will be executed by your runtime. A better understanding of that relationship -- between your code and your runtime -- will only make you a <i>better</i> programmer.</p>




